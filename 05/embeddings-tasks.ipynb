{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70776de8",
   "metadata": {},
   "source": [
    "- Text Classification: Assigning predefined categories to text based on its content.\n",
    "- Clustering: Grouping similar texts together based on their content.\n",
    "- Semantic Textual Similarity: Measuring how similar two pieces of text are in meaning.\n",
    "- Bitext Mining: Finding parallel sentences in different languages.\n",
    "- Reranking: Ordering a list of texts based on relevance to a query.\n",
    "- Pair Classification: Determining if two texts are related or not.\n",
    "- Multilabel Classification: Assigning multiple categories to a single piece of text.\n",
    "- Instruction Reranking: Ranking texts based on how well they follow given instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9bf9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/_github/massimodipaolo/ai-crash-course/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the embedding model\n",
    "model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6317a27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "1. TEXT CLASSIFICATION\n",
      "==================================================\n",
      "Text: Great film with excellent performances.\n",
      "Predicted: Positive\n",
      "\n",
      "Text: Not worth watching, very disappointing.\n",
      "Predicted: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. TEXT CLASSIFICATION\n",
    "# Classify movie reviews as positive or negative\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"1. TEXT CLASSIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Sample data\n",
    "train_texts = [\n",
    "    \"This movie was absolutely fantastic! I loved every minute.\",\n",
    "    \"Terrible film, waste of time and money.\",\n",
    "    \"An amazing masterpiece with brilliant acting.\",\n",
    "    \"Boring and predictable. Don't recommend.\",\n",
    "    \"Best movie I've seen this year!\",\n",
    "    \"Complete disaster, awful in every way.\"\n",
    "]\n",
    "train_labels = [1, 0, 1, 0, 1, 0]  # 1=positive, 0=negative\n",
    "\n",
    "test_texts = [\n",
    "    \"Great film with excellent performances.\",\n",
    "    \"Not worth watching, very disappointing.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "train_embeddings = model.encode(train_texts)\n",
    "test_embeddings = model.encode(test_texts)\n",
    "\n",
    "# Train classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Predict\n",
    "predictions = classifier.predict(test_embeddings)\n",
    "for text, pred in zip(test_texts, predictions):\n",
    "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "2. CLUSTERING\n",
      "==================================================\n",
      "Cluster 2: Apple announces new iPhone with advanced AI features\n",
      "Cluster 1: Stock market reaches all-time high today\n",
      "Cluster 0: New study shows benefits of Mediterranean diet\n",
      "Cluster 1: Tech giant unveils revolutionary smartphone technology\n",
      "Cluster 1: Wall Street celebrates record-breaking trading day\n",
      "Cluster 0: Researchers discover health benefits of olive oil\n"
     ]
    }
   ],
   "source": [
    "# 2. CLUSTERING\n",
    "# Group similar news articles\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"2. CLUSTERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "texts = [\n",
    "    \"Apple announces new iPhone with advanced AI features\",\n",
    "    \"Stock market reaches all-time high today\",\n",
    "    \"New study shows benefits of Mediterranean diet\",\n",
    "    \"Tech giant unveils revolutionary smartphone technology\",\n",
    "    \"Wall Street celebrates record-breaking trading day\",\n",
    "    \"Researchers discover health benefits of olive oil\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(texts)\n",
    "\n",
    "# Cluster into 3 groups\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "for i, (text, cluster) in enumerate(zip(texts, clusters)):\n",
    "    print(f\"Cluster {cluster}: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f4f9bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "3. SEMANTIC TEXTUAL SIMILARITY\n",
      "==================================================\n",
      "Sentence 1: A man is playing guitar\n",
      "Sentence 2: A person is playing a musical instrument\n",
      "Similarity: 0.7289\n",
      "\n",
      "Sentence 1: A dog is running in the park\n",
      "Sentence 2: The cat is sleeping on the couch\n",
      "Similarity: 0.2953\n",
      "\n",
      "Sentence 1: The weather is sunny today\n",
      "Sentence 2: It's a bright and clear day outside\n",
      "Similarity: 0.8234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. SEMANTIC TEXTUAL SIMILARITY\n",
    "# Measure similarity between sentence pairs\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"3. SEMANTIC TEXTUAL SIMILARITY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sentence_pairs = [\n",
    "    (\"A man is playing guitar\", \"A person is playing a musical instrument\"),\n",
    "    (\"A dog is running in the park\", \"The cat is sleeping on the couch\"),\n",
    "    (\"The weather is sunny today\", \"It's a bright and clear day outside\")\n",
    "]\n",
    "\n",
    "for sent1, sent2 in sentence_pairs:\n",
    "    emb1 = model.encode([sent1])\n",
    "    emb2 = model.encode([sent2])\n",
    "    similarity = cosine_similarity(emb1, emb2)[0][0]\n",
    "    print(f\"Sentence 1: {sent1}\")\n",
    "    print(f\"Sentence 2: {sent2}\")\n",
    "    print(f\"Similarity: {similarity:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65a81980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "4. BITEXT MINING\n",
      "==================================================\n",
      "EN: Hello, how are you?\n",
      "ES: Hola, ¿cómo estás?\n",
      "Score: 0.8297\n",
      "\n",
      "EN: The weather is nice today\n",
      "ES: El clima está agradable hoy\n",
      "Score: 0.8756\n",
      "\n",
      "EN: I love learning new languages\n",
      "ES: Me encanta aprender nuevos idiomas\n",
      "Score: 0.9278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. BITEXT MINING\n",
    "# Find parallel sentences in different languages\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"4. BITEXT MINING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "english_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"The weather is nice today\",\n",
    "    \"I love learning new languages\"\n",
    "]\n",
    "\n",
    "spanish_candidates = [\n",
    "    \"El clima está agradable hoy\",\n",
    "    \"Me encanta aprender nuevos idiomas\",\n",
    "    \"Hola, ¿cómo estás?\",\n",
    "    \"La comida es deliciosa\",\n",
    "    \"Estoy muy feliz hoy\",\n",
    "    \"¿Dónde está la biblioteca?\",\n",
    "    \"Buenos días, señor\",\n",
    "    \"El perro corre en el parque\"\n",
    "]\n",
    "\n",
    "en_embeddings = model.encode(english_sentences)\n",
    "es_embeddings = model.encode(spanish_candidates)\n",
    "\n",
    "# Find best match for each English sentence\n",
    "for i, en_sent in enumerate(english_sentences):\n",
    "    similarities = cosine_similarity([en_embeddings[i]], es_embeddings)[0]\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    print(f\"EN: {en_sent}\")\n",
    "    print(f\"ES: {spanish_candidates[best_match_idx]}\")\n",
    "    print(f\"Score: {similarities[best_match_idx]:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c95061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "5. RERANKING\n",
      "==================================================\n",
      "Query: machine learning algorithms\n",
      "\n",
      "Ranked documents:\n",
      "1. [0.8366] Support vector machines are supervised learning models\n",
      "2. [0.8101] Random forests and decision trees are popular ML algorithms\n",
      "3. [0.7485] Deep learning is a subset of machine learning using neural networks\n",
      "4. [0.3850] Use distilled water for better coffee taste\n",
      "5. [0.3378] How to bake a chocolate cake from scratch\n",
      "6. [0.3198] Gardening tips for growing tomatoes in summer\n",
      "7. [0.3118] The best pizza recipe includes mozzarella and basil\n"
     ]
    }
   ],
   "source": [
    "# 5. RERANKING\n",
    "# Order documents by relevance to a query\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"5. RERANKING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "query = \"machine learning algorithms\"\n",
    "documents = [\n",
    "    \"Deep learning is a subset of machine learning using neural networks\",\n",
    "    \"The best pizza recipe includes mozzarella and basil\",\n",
    "    \"Random forests and decision trees are popular ML algorithms\",\n",
    "    \"Gardening tips for growing tomatoes in summer\",\n",
    "    \"Support vector machines are supervised learning models\",\n",
    "    \"How to bake a chocolate cake from scratch\",\n",
    "    \"Use distilled water for better coffee taste\"\n",
    "]\n",
    "\n",
    "query_embedding = model.encode([query])\n",
    "doc_embeddings = model.encode(documents)\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "\n",
    "# Rerank by similarity\n",
    "ranked_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Ranked documents:\")\n",
    "for rank, idx in enumerate(ranked_indices, 1):\n",
    "    print(f\"{rank}. [{similarities[idx]:.4f}] {documents[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175c1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "6. PAIR CLASSIFICATION\n",
      "==================================================\n",
      "Training on 20 examples\n",
      "  - Related pairs: 10\n",
      "  - Unrelated pairs: 10\n",
      "\n",
      "APPROACH 1: Concatenated Embeddings\n",
      "--------------------------------------------------\n",
      "Q: What is machine learning?\n",
      "A: ML is a branch of artificial intelligence\n",
      "Classification: Related (confidence: 54.94%)\n",
      "\n",
      "Q: How to cook pasta?\n",
      "A: The capital of France is Paris\n",
      "Classification: Not Related (confidence: 62.21%)\n",
      "\n",
      "Q: What is Python?\n",
      "A: It's a high-level programming language\n",
      "Classification: Related (confidence: 53.82%)\n",
      "\n",
      "Q: How to play piano?\n",
      "A: Bitcoin is a cryptocurrency\n",
      "Classification: Related (confidence: 54.32%)\n",
      "\n",
      "Q: What causes rain?\n",
      "A: Water evaporates and condenses in clouds\n",
      "Classification: Not Related (confidence: 52.98%)\n",
      "\n",
      "\n",
      "==================================================\n",
      "APPROACH 2: Similarity-Based Classification\n",
      "--------------------------------------------------\n",
      "Q: What is machine learning?\n",
      "A: ML is a branch of artificial intelligence\n",
      "Similarity: 0.7525\n",
      "Classification: Related (confidence: 57.31%)\n",
      "\n",
      "Q: How to cook pasta?\n",
      "A: The capital of France is Paris\n",
      "Similarity: 0.3650\n",
      "Classification: Not Related (confidence: 55.80%)\n",
      "\n",
      "Q: What is Python?\n",
      "A: It's a high-level programming language\n",
      "Similarity: 0.5691\n",
      "Classification: Related (confidence: 51.12%)\n",
      "\n",
      "Q: How to play piano?\n",
      "A: Bitcoin is a cryptocurrency\n",
      "Similarity: 0.3390\n",
      "Classification: Not Related (confidence: 56.67%)\n",
      "\n",
      "Q: What causes rain?\n",
      "A: Water evaporates and condenses in clouds\n",
      "Similarity: 0.5903\n",
      "Classification: Related (confidence: 51.84%)\n",
      "\n",
      "\n",
      "==================================================\n",
      "APPROACH 3: Simple Similarity Threshold\n",
      "--------------------------------------------------\n",
      "(No training needed - just set a threshold)\n",
      "\n",
      "Q: What is machine learning?\n",
      "A: ML is a branch of artificial intelligence\n",
      "Similarity: 0.7525\n",
      "Classification: Related\n",
      "\n",
      "Q: How to cook pasta?\n",
      "A: The capital of France is Paris\n",
      "Similarity: 0.3650\n",
      "Classification: Not Related\n",
      "\n",
      "Q: What is Python?\n",
      "A: It's a high-level programming language\n",
      "Similarity: 0.5691\n",
      "Classification: Related\n",
      "\n",
      "Q: How to play piano?\n",
      "A: Bitcoin is a cryptocurrency\n",
      "Similarity: 0.3390\n",
      "Classification: Not Related\n",
      "\n",
      "Q: What causes rain?\n",
      "A: Water evaporates and condenses in clouds\n",
      "Similarity: 0.5903\n",
      "Classification: Related\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. PAIR CLASSIFICATION\n",
    "# Determine if two texts are related (e.g., question-answer pairs)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"6. PAIR CLASSIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "train_pairs = [\n",
    "    # Related pairs (label = 1)\n",
    "    (\"What is Python?\", \"Python is a programming language\", 1),\n",
    "    (\"How to bake a cake?\", \"Mix flour, eggs, and sugar then bake at 350°F\", 1),\n",
    "    (\"What's the weather?\", \"It's sunny and 75 degrees\", 1),\n",
    "    (\"How to code?\", \"Start with tutorials and practice regularly\", 1),\n",
    "    (\"What is machine learning?\", \"ML is a branch of AI that learns from data\", 1),\n",
    "    (\"How to cook pasta?\", \"Boil water, add pasta, cook for 10 minutes\", 1),\n",
    "    (\"What is JavaScript?\", \"JavaScript is a programming language for web development\", 1),\n",
    "    (\"How to lose weight?\", \"Eat healthy and exercise regularly\", 1),\n",
    "    (\"What is photosynthesis?\", \"Plants convert sunlight into energy\", 1),\n",
    "    (\"How to learn guitar?\", \"Practice chords and scales daily\", 1),    \n",
    "    # Unrelated pairs (label = 0)\n",
    "    (\"What is Python?\", \"The sky is blue\", 0),\n",
    "    (\"Best restaurants nearby?\", \"Python is a programming language\", 0),\n",
    "    (\"How to bake a cake?\", \"The capital of France is Paris\", 0),\n",
    "    (\"What's the weather?\", \"Dogs are loyal animals\", 0),\n",
    "    (\"How to code?\", \"Mount Everest is the tallest mountain\", 0),\n",
    "    (\"What is machine learning?\", \"Pizza has cheese and tomatoes\", 0),\n",
    "    (\"How to cook pasta?\", \"The ocean is very deep\", 0),\n",
    "    (\"What is JavaScript?\", \"Birds can fly south for winter\", 0),\n",
    "    (\"How to lose weight?\", \"Mars is a red planet\", 0),\n",
    "    (\"What is photosynthesis?\", \"Cars need gasoline to run\", 0),\n",
    "]\n",
    "\n",
    "test_pairs = [\n",
    "    (\"What is machine learning?\", \"ML is a branch of artificial intelligence\"),\n",
    "    (\"How to cook pasta?\", \"The capital of France is Paris\"),\n",
    "    (\"What is Python?\", \"It's a high-level programming language\"),\n",
    "    (\"How to play piano?\", \"Bitcoin is a cryptocurrency\"),\n",
    "    (\"What causes rain?\", \"Water evaporates and condenses in clouds\"),\n",
    "]\n",
    "\n",
    "print(f\"Training on {len(train_pairs)} examples\")\n",
    "print(f\"  - Related pairs: {sum(1 for _, _, label in train_pairs if label == 1)}\")\n",
    "print(f\"  - Unrelated pairs: {sum(1 for _, _, label in train_pairs if label == 0)}\\n\")\n",
    "\n",
    "# APPROACH 1: Concatenate embeddings\n",
    "print(\"APPROACH 1: Concatenated Embeddings\")\n",
    "print(\"-\" * 50)\n",
    "X_train = []\n",
    "y_train = []\n",
    "for q, a, label in train_pairs:\n",
    "    combined = model.encode([q, a])\n",
    "    X_train.append(np.concatenate(combined))\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "pair_classifier = LogisticRegression(max_iter=1000)\n",
    "pair_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "for q, a in test_pairs:\n",
    "    combined = model.encode([q, a])\n",
    "    X_test = np.concatenate(combined).reshape(1, -1)\n",
    "    prediction = pair_classifier.predict(X_test)[0]\n",
    "    probability = pair_classifier.predict_proba(X_test)[0]\n",
    "    result = \"Related\" if prediction == 1 else \"Not Related\"\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {a}\")\n",
    "    print(f\"Classification: {result} (confidence: {max(probability):.2%})\\n\")\n",
    "\n",
    "# APPROACH 2: Use similarity as feature (often better!)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"APPROACH 2: Similarity-Based Classification\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "X_train_sim = []\n",
    "for q, a, label in train_pairs:\n",
    "    q_emb = model.encode([q])\n",
    "    a_emb = model.encode([a])\n",
    "    similarity = cosine_similarity(q_emb, a_emb)[0][0]\n",
    "    # Use similarity as feature\n",
    "    X_train_sim.append([similarity])\n",
    "\n",
    "X_train_sim = np.array(X_train_sim)\n",
    "\n",
    "sim_classifier = LogisticRegression(max_iter=1000)\n",
    "sim_classifier.fit(X_train_sim, y_train)\n",
    "\n",
    "# Test\n",
    "for q, a in test_pairs:\n",
    "    q_emb = model.encode([q])\n",
    "    a_emb = model.encode([a])\n",
    "    similarity = cosine_similarity(q_emb, a_emb)[0][0]\n",
    "    X_test_sim = np.array([[similarity]])\n",
    "    \n",
    "    prediction = sim_classifier.predict(X_test_sim)[0]\n",
    "    probability = sim_classifier.predict_proba(X_test_sim)[0]\n",
    "    result = \"Related\" if prediction == 1 else \"Not Related\"\n",
    "    \n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {a}\")\n",
    "    print(f\"Similarity: {similarity:.4f}\")\n",
    "    print(f\"Classification: {result} (confidence: {max(probability):.2%})\\n\")\n",
    "\n",
    "# APPROACH 3: Simple threshold (no training needed!)\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"APPROACH 3: Simple Similarity Threshold\")\n",
    "print(\"-\" * 50)\n",
    "print(\"(No training needed - just set a threshold)\\n\")\n",
    "\n",
    "threshold = 0.5  # Adjust based on your needs\n",
    "\n",
    "for q, a in test_pairs:\n",
    "    q_emb = model.encode([q])\n",
    "    a_emb = model.encode([a])\n",
    "    similarity = cosine_similarity(q_emb, a_emb)[0][0]\n",
    "    \n",
    "    result = \"Related\" if similarity > threshold else \"Not Related\"\n",
    "    \n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {a}\")\n",
    "    print(f\"Similarity: {similarity:.4f}\")\n",
    "    print(f\"Classification: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2f8fba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "7. MULTILABEL CLASSIFICATION\n",
      "==================================================\n",
      "Article: Microsoft launches healthcare AI platform for financial analysis\n",
      "Categories: ['Technology', 'Health']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. MULTILABEL CLASSIFICATION\n",
    "# Assign multiple categories to articles\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"7. MULTILABEL CLASSIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Articles with multiple topics\n",
    "train_articles = [\n",
    "    \"Apple releases new AI-powered iPhone with health tracking features\",\n",
    "    \"Stock market analysis: Tech companies lead growth this quarter\",\n",
    "    \"Study shows exercise and diet improve mental health\",\n",
    "    \"Google announces cloud computing services for healthcare\",\n",
    "    \"Economic forecast: Technology sector shows strong performance\"\n",
    "]\n",
    "\n",
    "# Labels: [Technology, Finance, Health]\n",
    "train_labels = [\n",
    "    [1, 0, 1],  # Tech + Health\n",
    "    [1, 1, 0],  # Tech + Finance\n",
    "    [0, 0, 1],  # Health\n",
    "    [1, 0, 1],  # Tech + Health\n",
    "    [1, 1, 0]   # Tech + Finance\n",
    "]\n",
    "\n",
    "test_articles = [\n",
    "    \"Microsoft launches healthcare AI platform for financial analysis\",\n",
    "]\n",
    "\n",
    "# Train\n",
    "train_emb = model.encode(train_articles)\n",
    "test_emb = model.encode(test_articles)\n",
    "\n",
    "multilabel_clf = MultiOutputClassifier(LogisticRegression(max_iter=1000))\n",
    "multilabel_clf.fit(train_emb, train_labels)\n",
    "\n",
    "# Predict\n",
    "predictions = multilabel_clf.predict(test_emb)\n",
    "categories = [\"Technology\", \"Finance\", \"Health\"]\n",
    "\n",
    "for i, article in enumerate(test_articles):\n",
    "    print(f\"Article: {article}\")\n",
    "    assigned_cats = [cat for cat, pred in zip(categories, predictions[i]) if pred == 1]\n",
    "    print(\"Categories:\", assigned_cats)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "536d122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "8. INSTRUCTION RERANKING\n",
      "==================================================\n",
      "Instruction: Write a formal business email requesting a meeting\n",
      "\n",
      "Ranked responses:\n",
      "1. [Score: 0.7923]\n",
      "   To Whom It May Concern: I am writing to formally request a meeting at your earliest convenience. Sincerely, Jane Doe\n",
      "\n",
      "2. [Score: 0.7576]\n",
      "   Dear Mr. Smith, I would like to request a meeting to discuss the project timeline. Please let me know your availability. Best regards, John\n",
      "\n",
      "3. [Score: 0.6535]\n",
      "   I am reaching out to schedule a meeting to review our quarterly goals. Would next Tuesday work for you?\n",
      "\n",
      "4. [Score: 0.5610]\n",
      "   hey wanna meet up sometime? lmk\n",
      "\n",
      "5. [Score: 0.3588]\n",
      "   The weather is nice today\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. INSTRUCTION RERANKING\n",
    "# Rank texts based on how well instructions are followed\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"8. INSTRUCTION RERANKING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "instruction = \"Write a formal business email requesting a meeting\"\n",
    "\n",
    "candidate_texts = [\n",
    "    \"Dear Mr. Smith, I would like to request a meeting to discuss the project timeline. Please let me know your availability. Best regards, John\",\n",
    "    \"hey wanna meet up sometime? lmk\",\n",
    "    \"To Whom It May Concern: I am writing to formally request a meeting at your earliest convenience. Sincerely, Jane Doe\",\n",
    "    \"The weather is nice today\",\n",
    "    \"I am reaching out to schedule a meeting to review our quarterly goals. Would next Tuesday work for you?\"\n",
    "]\n",
    "\n",
    "# Encode instruction and candidates\n",
    "instruction_emb = model.encode([instruction])\n",
    "candidate_embs = model.encode(candidate_texts)\n",
    "\n",
    "# Calculate instruction-following scores\n",
    "scores = cosine_similarity(instruction_emb, candidate_embs)[0]\n",
    "\n",
    "# Rank by instruction-following quality\n",
    "ranked = np.argsort(scores)[::-1]\n",
    "\n",
    "print(f\"Instruction: {instruction}\\n\")\n",
    "print(\"Ranked responses:\")\n",
    "for rank, idx in enumerate(ranked, 1):\n",
    "    print(f\"{rank}. [Score: {scores[idx]:.4f}]\")\n",
    "    print(f\"   {candidate_texts[idx]}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-crash-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
